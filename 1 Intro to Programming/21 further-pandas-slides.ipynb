{"cells": [{"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# Further Pandas"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib\n", "import matplotlib.pyplot as plt\n", "\n", "df = pd.read_csv('data/countries.csv')\n", "\n", "from IPython.display import HTML\n", "np.random.seed(1)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Pandas Basics\n", "\n", "* Useful **methods** and **functions**\n", "    * `describe`, `get_dummies`, etc.\n", "* **Indexing**\n", "    * `loc` vs. `iloc`\n", "* **Column-wise** operations\n", "    * `arithmetic`, `apply`, etc.\n", "* **SQL** inspired functions\n", "    * `merge`, `join`, `groupby`"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["In the Introduction to Pandas module we went over the basics of Pandas, covering DataFrames and the fundamental operations used to extract information from them.\n", "\n", "We looked at useful methods and functions, multiple ways to index DataFrames, column-wise operations for applying functions to different attributes, and SQL-style functions. \n", "\n", "If you aren't familiar with any of these topics then it may be worth going back to recap."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Advanced Processing Functions\n", "* Pivot Tables\n", "    * `pivot`, `pivot_table`, `melt`\n", "* Multi-Index\n", "    * `MultiIndex`, `stack`, `crosstab`\n", "* Pandas `Series`  \n", "    * `factorize`, `cut`"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["In this module we're going to talk about some of the advanced functionality `pandas` can offer us. \n", "\n", "The topics are broadly split up into three categories: pivot tables, multi-indices, and Series objects. \n", "\n", "These are three different advanced aspects of `pandas` that may appear less often than the fundamental operations but are nonetheless extremely useful to understand. You'll also find that their usage is fairly idiomatic of Python libraries in general, so a good understanding of the advanced `pandas` features is a very transferrable skillset!\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Pivot Tables\n", "* Similar to pivot tables in **Excel**\n", "* Reshape a dataset, so each row has a **category** and **subcategory** associated to a **value**\n", "    * example: Great Britain's (category: country) online sales (subcategory: online) make a profit (value: profit) of X"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["Pivot tables in `pandas` are very similar to pivot tables in Excel. The idea behind them is to reshape a dataframe such that each row of the index column represents an individual category, with subcategories and values stored in separate columns.\n", "\n", "For example, we could consider a dataset with profits from companies based in different countries split into subcategories: online and in-store sales. \n", "\n", "These subcategories have associated values (in this case profits).\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Example"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["import pandas as pd\n", "df = pd.read_csv('data/profits.csv')\n", "\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["* The **category** is the **country**.\n", "* The **sub-category** is the **type**.\n", "* The **value** is the **profit**\n", "\n", "We want to pivot the table so that there is only one copy of each country in the country column."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["Consider this example where we have online and in-store sales for two countries. We have them stored in a flat format, so there are duplicates in the 'Country' and the 'Type' columns. \n", "\n", "Using pivot tables we can reshape these into a dataframe which has 'Country' as the broad category, 'Type' as the subcategory, and 'Profit' as the value.\n", "\n", "The goal of the pivot table is to reshape the elements so that we have 'Country' as an index (i.e. there is one of each country in the country column)."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Example `df.pivot`:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df.pivot(index='Country', columns='Type')"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["To use `df.pivot`, we provide a new index, which in this case is 'Country', which is the column we would like to compress down to one of each type. \n", "\n", "In order to do this we need to create new columns for each subcategory: here, the subcategories are in-store and online sales, which previously were defined in the column 'Type'. \n", "\n", "In this example we specify the index 'Country' and the column(s) 'Type' and pandas reshapes the dataframe into a format with 'Country' as the index, and columns specified by the possible values of 'Type'."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Pivot Tables\n", "\n", "There are two functions to build pivot tables in pandas:\n", "* `.pivot(index, columns, [values])`\n", "    * **numerical** and **categorical** data\n", "    * no aggregation - will fail if there are **duplicate rows** with same categories\n", "* `.pivot_table(index, columns, [values], [aggfunc])`\n", "    * only with **numerical** data\n", "    * can do aggregation (similar to `groupby`)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["There are two different ways to make pivot tables in `pandas`. The first we have already seen: `.pivot`. \n", "\n", "`.pivot` takes two compulsory arguments (index and columns) but can also be specified to be applied only to values (profits here) that meet a certain criterion. `.pivot` can be applied to both numerical and categorical data but as a consequence won't do any aggregation. If, in the example above, there had been multiple rows for GB in-store sales, `.pivot` would have thrown an exception because it doesn't know how to combine them. \n", "\n", "By contrast, `pivot_table` only works with numerical data and so can aggregate duplicate rows. We can specify an aggregation function --- e.g. in the example above we may have wanted to *sum* the different sales subcategories over several quarters or years."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## `df.pivot`\n", "\n", "* `.pivot` works with numerical and categorical data (if rows are unique per subcategory)\n", "    * `index`: the column that will become the new index\n", "    * `columns`: the subcategories to split by\n", "    * `values`: [optional] if you want to keep subset of columns"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["To recap, `.pivot` works with **both** numerical **and** categorical data - with the requirement that rows are unique per subcategory. \n", "\n", "We must define the new index, as well as the subcategories we're going to split the data into. We can optionally specify a subset of the columns to keep using the keyword `values`. "]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## `df.pivot`\n", "\n", "In the previous example, what was the original index?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Is there another column that we could use as the index?"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["In the previous example, we specified that the new index was 'Country'. What was the original index? \n", "\n", "We hadn't supplied one, so pandas had automatically constructed an index from 0 to 3 for us. So when we remove the duplicates by splitting up the profits into \"online\" and \"in-store\" profits, we set 'Country' to be the new index.\n", "\n", "Is there a different column that we could use as a new index (apart from 'Country' and the original index)?"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## `df.pivot`\n", "\n", "Yes! We could pivot on the `Type`:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df.pivot(index='Type', columns='Country')"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["Yes, there is another column: we could use the 'Type' as the index to pivot to. This sets the index to be each of the unique values of 'Type', which are 'online' and 'in-store'. Each of these needs to be split across each country, so we also get one row per country (GB and US). \n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## `df.pivot_table`\n", "* `pivot_table` **only numerical data** and we can add an aggregator:\n", "    * `index`: the columns that will become the new index\n", "    * `columns`: the subcategories to split by\n", "    * `values`: [optional] subset of columns to keep\n", "    * `aggfunc`: [optional] aggregation function for duplicate rows"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["`.pivot` may not always be suitable because we aren't allowed to have duplicate rows for each subcategory. \n", "\n", "For example, we might have online and in-store results for each quarter and we'd like the pivot table values to be the total for the year. We need to aggregate or sum over each quarter. \n", "\n", "For this purpose we can use `pivot_table` instead of `pivot`. We still pass in an index, columns, and optionally a specific subset of values, but we can also specify an aggregation function (for example, sum). \n", "\n", "Note that `pivot_table` only works with numerical data, where `pivot` can use either numerical or categorical data. "]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Example `df.pivot_table`:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df = pd.read_csv('data/profits_with_duplicates.csv')\n", "df"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["Consider this example, which is similar to the previous example but now includes duplicates of the subcategory \"Type\".\n", "\n", "`pivot` would throw an exception if we passed this table, because it does not have an aggregation function. "]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Example `df.pivot_table`:\n", "\n", "* `df.pivot` fails because it can't aggregate"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df = df.pivot_table(index='Country', columns='Type', aggfunc='sum')\n", "df"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["In this case we can instead use `pivot_table` and pass in the optional argument 'sum' as the aggfunc. The default functionality is to take the mean, but we want to sum here so we specify 'sum' as the aggfunc. \n", "\n", "You can see that the `pivot_table` operation has set 'Country' as the new axis just as before, so there are no duplicates of each country in the column. We have the same new columns as when we used `pivot`, except this time the duplicate subcategories have been summed (i.e. in-store sales for each country are now summed into one entry). \n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## `melt`\n", "* Reverses the `pivot` operation\n", "* Reshape so we have a column of **categories** (e.g. country) which has **one value** (e.g. profit) **per subcategory**) \n", "* Arguments:\n", "    * `id_vars`: the index column to be stretched out\n", "    * `value_vars`: the new subcategory (could be multiple of these)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["`melt` is the inverse of the `pivot` operation. Where before we were moving the category (for us, country) into the index position, and creating columns for each subcategory, we are now reshaping so that we have a column of the category with one row per subcategory entry. In this case our subcategories are 'in-store' and 'online' so this means that per country we would have two rows for the country `GB` and two rows for the country `US`. \n", "\n", "`melt` takes two key arguments: `id_vars` which is the index column corresponding to the broad category, and `value_vars` which is the new subcategory. We could choose to pass multiple subcategories but for now we'll use one for clarity. "]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Example `melt`:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df = pd.read_csv('data/profits.csv')\n", "df = df.pivot(index='Country', columns='Type')\n", "\n", "# MultiIndex processing - this will be covered in the next section\n", "df = df['Profit'].reset_index() \n", "\n", "df"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["pd.melt(df, id_vars='Country', var_name='Type', value_name='Profit')"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["Consider the example we had earlier where we used `pivot` to set country as the index and have one column for in-store and one column for online sales. \n", "\n", "We have to do a little pre-processing because of Multi-Indexing, which is something you can skip for now and we'll cover in the next section.\n", "\n", "We use `melt` to reshape the DataFrame so that we have one row for each of the `value_vars` we specified, which are subcategories to the `id_vars` we gave.\n", "\n", "You can see that this reverts us back to the DataFrame we had originally. You can think of the original shape as being 'long' and the pivoted shape as being 'wide' - different scenarios will dictate which one we prefer, but pandas thankfully makes it easy to move between them."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## MultiIndex\n", "* Hierarchical index over several **columns** or **rows**\n", "    * `pivot` (and some other commands) create a multi-index by default\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df = pd.read_csv('data/profits.csv')\n", "df = df.pivot(index='Country', columns='Type')\n", "df"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["'Profit' is a multi-index with subcolumns."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["We have already mentioned that pre-processing of a pivot table can be done with `melt`. This is because `pivot`, by default, creates a MultiIndex. \n", "\n", "A MultiIndex is a way to encapsulate several columns or rows in a group. In our example, in-store and online are subcategories of 'Profit' - they now have a built-in abstraction for being different types of profit. This can be a natural way to express hierarchies of attributes instead of having them in a flat table. "]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Column MultiIndex\n", "\n", "Imagine our data is set up in lists:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# [online, in-store]\n", "gb = [30, 40]\n", "us = [100, 25]\n", "\n", "df = pd.DataFrame([gb,us], columns=['online','in-store'])\n", "df"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["We could combine online and in-store into a MultiIndex called \"profit\"."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["A MultiIndex can be used to group together either columns or rows. \n", "\n", "Let's start with columns. Imagine this example where we have the DataFrame set up with two columns, and we would like to group the two columns together into a 'Profit' MultiIndex. "]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Column MultiIndex\n", "\n", "Create in three ways: `from_tuples`,`from_arrays`,`from_frames`"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# single index:\n", "df = pd.DataFrame([gb,us], columns=['online','in-store'])\n", "\n", "# MultiIndex:\n", "columns = pd.MultiIndex.from_tuples([('profit','online'), ('profit','in-store')])\n", "df = pd.DataFrame([gb,us], columns=columns)\n", "df"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["`pandas` offers three methods for creating a MultiIndex: from tuples, arrays, set products, or dataframes; all of which work very similarly.\n", "\n", "Previously we created a single index by passing in a flat list of columns. To create a MultiIndex, we can pass in a  list of tuples that express the hierarchical mapping from the category to the subcategories. In this case the category is 'profit' and the subcategories are 'online' and 'in-store'. \n", "\n", "Once we have the MultiIndex object, we can create the dataframe as we did before, this time passing the MultiIndex in as the columns (where before we were just passing a flat list). "]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Column Multi-Index\n", "\n", "We can chain index or use `loc`:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df['profit']['online']"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df.loc[:, ('profit', 'online')]"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["We can continue to index the DataFrame as before, either by chaining together indices in the order category followed by subcategory, or by using `loc`. \n", "\n", "In this example we use the colon to denote that we would like all of the rows, and we use a tuple to specify which category and subcategory we would like to access. If we indexed an individual row then we would get only the online profit for that row."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Row MultiIndex"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["london    = [100,20]\n", "cambridge = [200,30]\n", "new_york  = [300,40]\n", "\n", "index = pd.MultiIndex.from_tuples([('GB','London'),('GB','Cambridge'),('US','New York')])\n", "\n", "df = pd.DataFrame([london, cambridge, new_york], columns=['profit', 'revenue'], index=index)\n", "\n", "df"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["Very similarly we can create a MultiIndex for rows - in this example we are grouping together cities by their country. \n", "\n", "The syntax is very similar, except this time instead of passing in the MultiIndex to the columns keyword we are passing it in as an Index. This makes sense for a row MultiIndex because the Index is what we use to access each of the rows. \n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Row MultiIndex\n", "\n", "We select row subsets in a similar way:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df.loc[\"GB\", :]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df.loc[(\"GB\", \"London\"),:]"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["The row MultiIndex can be accessed with the usual pandas `loc` syntax. We can access columns using square brackets,\n", "but we need `loc` in order to access via the index of the DataFrame. \n", "\n", "Here are two examples. In the first example, we ask for all columns with \"GB\" as the category using the colon in the column index. We index via [rows, columns] so a colon after the comma indicates we want all of the columns (profit and revenue).\n", "\n", "In the second example we pass a tuple in order to navigate the hierarchy and specify that we want the country and city \"GB\" and \"London\", and then we ask for all the columns.\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Stack and Unstack\n", "\n", "* Stack: converts inner **column** MultiIndex to a **row** MultiIndex\n", "* Unstack: converts inner **row** MultiIndex to a **column** MultiIndex"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["`stack` and `unstack` are pandas methods for transposing a MultiIndex, and they interact a little like `pivot` and `melt`. \n", "\n", "We use `stack` when we have a column MultiIndex and we'd like a row MultiIndex. When we want to do the opposite we use `unstack`. Note that the hierarchy is preserved, it's just transposed: we are not flattening any indices here."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Stack\n", "\n", "Consider the **column** MultiIndex we created earlier:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["gb = [30, 40]\n", "us = [100, 25]\n", "\n", "columns = pd.MultiIndex.from_tuples([('profit','online'), ('profit','in-store')])\n", "df = pd.DataFrame([gb,us], columns=columns, index=['GB','US'])\n", "df"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["`stack` flattens \"profit\" into a single column, multi-indexed by rows \"online\" and \"in-store\"."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["Consider the example we had earlier where we created a column multiindex for different types of profit.\n", "\n", "In this case we might want to have a single column for profit and instead have a row MultiIndex for each of the types of profit, so we could use `stack` to transpose the dataframe."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Stack "]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df.stack()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["This might not seem particularly natural in this case, but hopefully it is a good illustration of exactly what to expect from `stack`. \n", "\n", "When we apply `stack`, profit becomes one column, and each country is subcategorised by a row for each type of profit we have. "]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Unstack\n", "\n", "Unstack does the opposite, converting the row MultiIndex back to a column MultiIndex:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df = df.stack()\n", "df.unstack()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["By contrast, if we had the row MultiIndex and we instead wanted a column MultiIndex we could use `unstack`, which works just as we would expect, reverting the dataframe back to its previous state. \n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Crosstab\n", "\n", "Use `crosstab` to compare aggregations of different values."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df = pd.read_csv('data/profits_with_duplicates.csv')\n", "df"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["e.g. `crosstab` could `sum` the profits for each country."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["Consider again case where we have duplicate rows for each of the subcategories and we haven't created a pivot or a MultiIndex yet. \n", "\n", "`crosstab` is used to tabulate different columns in the DataFrame. Often its most common usage is to count the number of occurences of each subcategory (e.g. recording the number of entries we have for each country/profit type). \n", "\n", "Another usage might be to use it to sum the total profits, as an alternative to using `pivot_table`. "]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## `crosstab` example"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["pd.crosstab(df['Country'], columns=df['Type'], values=df['Profit'], aggfunc='sum')"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["The syntax is very similar to `pivot_table` and in the case the result is also very similar. We specify an `index`, in this case 'Country', and the column that contains the subcategories, in this case 'Type'. \n", "\n", "We also have to specify the values which we want to aggregate, and the aggfunc we want to use (in this case, sum). \n", "\n", "`crosstab`, like `pivot_table`, will return a MultiIndex which you can see here. \n", "\n", "You might wonder what the difference is between the two. \n", "\n", "In general, `crosstab` is very useful for making simple analyses when there isn't a need to filter down the result, and we want things like frequency tables or small tabulations. `pivot_table` allows us to express more complicated queries by letting us use grouping over the index and columns."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## `cut`\n", "\n", "Transform **numerical** data into **categorical** data\n", "* group numbers into histogram bins\n", "* each value is replaced by the number it bins to "]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["a = np.linspace(0, 9, 10)\n", "a"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["* e.g. imagine we want to split these numbers up into two bins (<=5 and >5)."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["`cut` is another useful pandas function, which we can use to quantise numerical data into categorical groups. A simple example is that we might want to compress a list of numbers from 0 to 9 into two groups. \n", "\n", "`cut` automatically splits these into two bins, and returns a list with the invidual values replaced by their bin."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## `cut`"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["binned = pd.cut(a, bins=2)\n", "binned"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["binned.categories"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["This might look a bit strange at first. `pandas` has replaced every value in the list with the range it fits into (either 0 to 4.5 or 4.5 to 9). It also has a `categories` attribute which tells us what the two intervals are.\n", "\n", "The range opens with a curved bracket and ends with a square bracket, with the square bracket meaning that that number is inclusive. So in the second bin 4.5 is exclusive, and 9.0 is inclusive. This means that the number 4.5 would be grouped into the first bin.\n", "\n", "We can now use this numerical data as categorical data instead, or use it to easily create histograms."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## `factorize`\n", "\n", "* `factorize` splits data into a dataset `codes, uniques`, assigning a code to each unique value"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["codes, uniques = pd.factorize(['GB','GB','US','FR','GB','FR','FR'])\n", "print(codes)\n", "print(uniques)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["uniques[codes[0]]"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["`factorize` works by assigning a code to each unique value in a dataset. In this case we have a list of countries with duplicates. \n", "\n", "We can `factorize` the list into a pair of codes and unique values, with the uniques representing each of the unique country labels. The values are then replaced by their code, which we can use to index uniques to retrieve the original value. \n", "\n", "This might be useful for example if we had a very large dataset with lots of duplicates: it may be cheaper to store duplicates of the integer codes than of long strings.  However, its main use is in scenarios where we only care about whether or not entries are distinct (and not their actual value). "]}], "metadata": {"@webio": {"lastCommId": null, "lastKernelId": null}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7"}}, "nbformat": 4, "nbformat_minor": 2}