{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7"}}, "nbformat": 4, "nbformat_minor": 4, "cells": [{"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# Introduction to ensemble methods\n", "\n", "In this practical, you will construct your own bagging ensemble, to boost performance on a binary classification problem.\n", "\n", "\n", "## The problem\n", "\n", "Users of your service sometimes close their accounts, even though they have been with you for a while. It would be useful if you could predict which ones are likely to do this, before it happens, so you can take action to retain their custom.\n", "\n", "You have access to 20 different features for each user, based on data such as how often they log in, how many purchases they make, etc. The aim is to see if you can predict whether a user will end up closing their account or not.\n", "\n", "## Getting started\n", "\n", "First, load the data from `account_data.csv` using `pandas` into a DataFrame called `data`. \n", "\n", "Find out how many users left the service by examining the `closed_account` column. \n", "\n", "*Hint: use the `.value_counts()` method*"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["import pandas as pd\n", "\n", "# Your code here...\n", "\n", "data = pd.read_csv('data/account_data.csv')\n", "\n", "print(data['closed_account'].value_counts())\n", "\n", "print('Around half the accounts closed.')\n", "\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Setting up for classification - I\n", "\n", "Before proceeding, we will split the data into training and testing subsets.\n", "\n", "Create two variables, `X` and `y`, from the `data` DataFrame.\n", "\n", "`X` should be all the columns that you want to use in your prediction (ie. all except for `closed_account`)\n", "\n", "`y` should be the column that you are trying to predict (ie. `closed_account`)\n", "\n", "These are the conventional variable names used in machine learning to represent your predicting features (`X`) and the values you are trying to predict (`y`)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "\n", "X = data.drop('closed_account', axis=1)\n", "y = data['closed_account']\n", "\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Setting up for classification - II\n", "\n", "Models will have access to the training set in order to learn, but we will evaluate them on the unseen test set.\n", "\n", "Use `train_test_split` from `sklearn.model_selection` to split the data up. \n", "\n", "This function takes your `X` and `y` (our 20 monthly data points, and the closed/not closed label) and splits them up. It returns four lists - one `X` for each of train/test and the same for `y`.\n", "\n", "The default gives a ratio of 3:1 train/test split.\n", "\n", "Call the new variables `X_train`, `X_test`, `y_train`, and `y_test`.\n", "\n", "(Set `random_state` to `5`, so that results are the same every time!)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "# Your code here...\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5)\n", "\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Single model performance - I\n", "\n", "Before trying an ensemble, we need some baselines in order to determine whether the ensemble method actually improved anything.\n", "\n", "We will use a simple Naive Bayes classifier here with default parameters.\n", "\n", "Import the required class and instantiate it with the variable name `model`.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.naive_bayes import GaussianNB\n", "\n", "# Your code here...\n", "\n", "model = GaussianNB()\n", "\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Single model performance - II\n", "\n", "Use the `.fit()` method of the model to train it on the training subset of the data.\n", "\n", "Use the `.score()` method the same way, using the same data, to see how well it performs on the data it learned from.\n", "\n", "Use `model.predict()` to generate predictions for `X_train` and compare these predictions to the ground truth (`y_train`) using a classification report."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.metrics import classification_report\n", "\n", "# Your code here...\n", "\n", "model.fit(X_train, y_train)\n", "\n", "print(f\"Accuracy on observed data: {model.score(X_train, y_train):.2f}\")\n", "\n", "y_pred = model.predict(X_train)\n", "\n", "print(classification_report(y_train, y_pred))\n", "\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Single model performance - III\n", "\n", "Repeat the above scoring process but now use the unseen test data.\n", "\n", "Do you expect accuracy to change? If so, in what direction?\n", "\n", "What are your thoughts on how well the model performs on the two classes?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "\n", "y_pred = model.predict(X_test)\n", "\n", "print(f\"Accuracy on unseen data: {model.score(X_test, y_test):.2f}\")\n", "\n", "print(\"Accuracy is far lower on the unseen data, which is to be expected.\")\n", "\n", "print(classification_report(y_test, y_pred))\n", "\n", "print(\"The model does quite poorly on the class we are most interested in - the users that will close their accounts.\")\n", "\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Bagging ensemble - I\n", "\n", "Now let's see what effect a simple bagging ensemble has.\n", "\n", "`sklearn` has a useful utility class that will handle this for us: `sklearn.ensemble.BaggingClassifier`\n", "\n", "This has several parameters which can be tuned but the main ones are:\n", "\n", "`base_estimator` - the model to use\n", "\n", "`n_estimators` - how many models to use. Default is 10.\n", "\n", "`random_state` - ensures the same results every time\n", "\n", "Create a bagging classifier named `ensemble`, using `GaussianNB()` as the `base_estimator`. Keep `n_estimators` at 10 and set `random_state` to 5."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.ensemble import BaggingClassifier\n", "\n", "# Your code here...\n", "\n", "ensemble = BaggingClassifier(\n", "    base_estimator=GaussianNB(),\n", "    n_estimators=10,\n", "    random_state=5\n", ")\n", "\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Bagging ensemble - II\n", "\n", "Once you have created this meta-model, it works exactly the same way as any model in `sklearn` - it has  methods like `.fit()` and `.score()` and `.predict()`.\n", "\n", "Repeat the training/scoring/classification report process from the single model approach you did previously.\n", "\n", "Train only on the training data and test only on the test data.\n", "\n", "What do you observe now?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "\n", "ensemble.fit(X=X_train, y=y_train)\n", "\n", "print(f\"Ensemble accuracy on unseen data: {ensemble.score(X_test, y_test):.2f}\")\n", "\n", "y_pred = ensemble.predict(X_test)\n", "\n", "print(classification_report(y_test, y_pred))\n", "\n", "print(\"Performance for both classes has improved quite a bit, though the most important class (1) is still quite hard to predict accurately.\")\n", "print(\"We are performing marginally better than random guessing, so you could flip a coin to decide and get similar results!\")\n", "\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Conclusions\n", "\n", "Using an ensemble of methods improved performance in a binary classification task by a good margin, though performance was still generally quite low.\n", "\n", "This may be because the signal to noise ratio in the data is low (we have used synthetic data), meaning the model needs to make predictions with very little information. Even so, what could you investigate in order to improve performance on this task?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code below\n", "\n", "print(\"The Naive Bayes model may not be the best suited to this task. You could try an SVM or Logistic Regression. It would be as simple as changing the base_estimator.\")\n", "print(\"Perhaps more estimators are needed in the ensemble, or fewer. You could vary this and observe the effect on performance.\")\n", "print(\"There might not be enough training data to learn from. Try adjusting the ratio of train:test data from 75:25 to perhaps 90:10.\")\n", "\n"]}]}