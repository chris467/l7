{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7"}}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# Part 1: Introduction to Decision Trees\n", "\n", "Let's import the packages that we will use during the practical:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import seaborn as sns"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### The dataset"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["The dataset is available in the `data/` directory, but it can be also downloaded from [here](https://archive.ics.uci.edu/ml/datasets/bank+marketing). It consists of data from marketing campaigns of a Portuguese bank. We will try to build a classifier that can predict whether or not the client targeted by the campaign ended up subscribing to a term deposit (column `y`).\n", "\n", "Load the file `data/bank-marketing.c` with `pandas` and check the distribution of the target `y`. Here the separator is `';'` instead of a comma.\n", "\n", "Save the DataFrame as `df`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "df = pd.read_csv(\"data/bank-marketing.csv\",sep=\";\")\n", "df['y'].value_counts()\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["The dataset is imbalanced, so we will need to keep that in mind when building our models!"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Now split the data into the feature matrix `X` (all features except `y`) and the target vector `y`, making sure that you convert `yes` to `1` and `no` to `0`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Get X, y\n", "# Your code here...\n", "y = df[\"y\"].map({\"no\":0, \"yes\":1})\n", "X = df.drop(\"y\", axis=1)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Here is the list of features in our `X` matrix:"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["| | | |\n", "| --- | --- | --- |\n", "age | | numeric \n", "job | type of job | categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown'\n", "marital | marital status | categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed\n", "education | | categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown'\n", "default | has credit in default? | categorical: 'no','yes','unknown'\n", "housing | has housing loan? | categorical: 'no','yes','unknown'\n", "loan | has personal loan? | categorical: 'no','yes','unknown'\n", "contact | contact communication type | categorical: 'cellular','telephone'\n", "month | last contact month of year | categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec'\n", "day_of_week | last contact day of the week | categorical: 'mon','tue','wed','thu','fri'\n", "duration | last contact duration, in seconds | numeric. Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n", "campaign | number of contacts performed during this campaign and for this client | numeric, includes last contact\n", "pdays | number of days that passed by after the client was last contacted from a previous campaign | numeric; 999 means client was not previously contacted\n", "previous | number of contacts performed before this campaign and for this client | numeric\n", "poutcome | outcome of the previous marketing campaign | categorical: 'failure','nonexistent','success'\n", "emp.var.rate | employment variation rate - quarterly indicator | numeric\n", "cons.price.idx | consumer price index - monthly indicator | numeric\n", "cons.conf.idx | consumer confidence index - monthly indicator | numeric\n", "euribor3m | euribor 3 month rate - daily indicator | numeric \n", "nr.employed | number of employees - quarterly indicator | numeric"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Note the comment about the `duration` feature. We will exclude it from our analysis.\n", "\n", "Drop `duration` from `X`:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "X.drop(\"duration\", inplace=True, axis=1)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Now we can check the types of all our features. We see that some seem to be categorical whilst others are numerical. We will keep two lists, one for each type, so we can preprocess them differently."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["X.dtypes"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# when there is a third class \"unknown\", we'll process the feature as non-binary categorical\n", "num_features = [\"age\", \"campaign\", \"pdays\", \"previous\", \"emp.var.rate\", \n", "                \"cons.price.idx\", \"cons.conf.idx\",\"euribor3m\", \"nr.employed\"]\n", "\n", "cat_features = [\"job\", \"marital\", \"education\",\"default\", \"housing\", \"loan\",\n", "                \"contact\", \"month\", \"day_of_week\", \"poutcome\"]"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Visualise the numerical features\n", "\n", "Using `seaborn`, show a boxplot of the numerical features."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "plt.figure(figsize=(20, 10))\n", "sns.boxplot(data=X[num_features], ax=plt.gca())\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["The features aren't at the same scale. But that's fine for tree-based methods as we've said in the lesson, so we do not need to do any scaling here!"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### One-hot encoding on categorical features"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["The `sklearn` implementation of decision trees cannot work directly with categorical features, so we need to make sure our dataset contains only numbers. Consequently, we will need to transform our categorical features into one-hot encoded features.\n", "\n", "To do so, use `pd.get_dummies` on our DataFrame (select only the categorical features - we already have them stored in the variable `cat_features`) to generate the new columns.\n", "\n", "Assign the new DataFrame to a variable `X_categorical`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "X_categorical = pd.get_dummies(X[cat_features])\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Create a Dataframe with only our numerical features (we have their names stored in the variable `num_features`) from `X` together with the `X_categorical` DataFrame.\n", "\n", "Use `pd.concat` (making sure to specify the correct axis!) and call the new DataFrame `X_processed`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["X_processed = pd.concat([X[num_features], X_categorical], axis=1)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Split the data into training and test sets"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Split the data (use `X_processed`) into a training set and test set. Here we are dealing with an imbalanced dataset, so it is important to enforce stratification. We will use the argument `stratify` from `train_test_split` to do so (check the documentation).\n", "\n", "Call the new variables `X_train`, `X_test`, `y_train`, and `y_test`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "from sklearn.model_selection import train_test_split\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(\n", "    X_processed,\n", "    y,\n", "    test_size=.3,\n", "    random_state=42,\n", "    stratify=y\n", ")\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Train a decision tree\n", "\n", "Now that we have done our preprocessing and our data is ready, we can train a decision tree. We will use `DecisionTreeClassifier` from `sklearn.tree`.\n", "\n", "For now we will keep our tree unconstrained with:\n", "- `max_depth=None`\n", "- `min_samples_split=2`"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Create a new decision tree, assigning it to the variable `dtc`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "from sklearn.tree import DecisionTreeClassifier\n", "\n", "dtc = DecisionTreeClassifier(max_depth=None, min_samples_split=2)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Now fit the model on the training set:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "dtc.fit(X_train, y_train)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Execute the cell below to display the tree in the notebook, what do you observe?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn import tree\n", "\n", "plt.figure(figsize=(200, 20))\n", "tree.plot_tree(dtc, \n", "               filled=True, \n", "               rounded=True,\n", "               max_depth=6,\n", "               proportion=True,\n", "               fontsize=10,\n", "               feature_names=X_train.columns)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Compute the accuracy of the model on the training data and then on the test data, what can you tell?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "from sklearn.metrics import accuracy_score\n", "\n", "print(accuracy_score(y_train, dtc.predict(X_train)))\n", "print(accuracy_score(y_test, dtc.predict(X_test)))\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Now let's investigate a bit more by looking at the `classification_report` (you can import it from `sklearn.metrics`) for our test set. That will provide us with more information about precision and recall on both our classes."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "from sklearn.metrics import classification_report\n", "\n", "print(classification_report(y_test, dtc.predict(X_test)))\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["It looks like our model is predicting the majority class `0` (no) really well, which leads to a high accuracy, but we're really bad at predicting class `1`, which corresponds to successful campaigns and is of interest here!"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# Part 2: Parameter Tuning and Feature Importance"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Parameter tuning"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["We've found two major issues with our model so far:\n", "\n", "- It greatly overfits\n", "- It focuses on the majority class"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["With our decision tree, we can address both. \n", "\n", "- For the first issue we will need to tune `max_depth` and `min_samples_split`. \n", "- For the second issue, we will set `class_weight='balanced'` so that it automatically gives more weight to our minority class as a way to compensate."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Exploration of different parameters"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Let's use more sensible/constraining values for `max_depth` and `min_samples_split`, let's say `6` and `20` respectively.\n", "\n", "To change the parameters of the existing tree classifier `dtc`, you can use `set_params` on it with the name and values you want to update (for example `max_depth=6`).\n", "\n", "Don't forget to re-train the tree after changing the parameters."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "dtc.set_params(max_depth=6, min_samples_split=20)\n", "dtc.fit(X_train, y_train)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Let's check the accuracy on both the train and the test set. Is it better than before?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "from sklearn.metrics import accuracy_score\n", "\n", "print(accuracy_score(y_train, dtc.predict(X_train)))\n", "print(accuracy_score(y_test, dtc.predict(X_test)))\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["We can also visualise our tree:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["plt.figure(figsize=(120, 12))\n", "tree.plot_tree(dtc, \n", "               filled=True, \n", "               rounded=True,\n", "               max_depth=6,\n", "               proportion=True,\n", "               fontsize=10,\n", "               feature_names=X_train.columns)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["That's a simpler tree!\n", "\n", "Let's have a look at the classification report now for the test set:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "dtc.fit(X_train, y_train)\n", "print(classification_report(y_test, dtc.predict(X_test)))\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["It is still doing really badly on class `1`. Try to set the parameter `class_weight` to `\"balanced\"` and retrain the tree:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "dtc.set_params(class_weight=\"balanced\")\n", "dtc.fit(X_train, y_train)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Check the classification report again:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "print(classification_report(y_test, dtc.predict(X_test)))\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["That's much better!"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Use grid search to find the optimal parameters"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Now that we've observed the impact of various parameters, we can do a grid search to find the optimal ones.\n", "\n", "Define a new `parameters` dictionary that contains all the values you want to try for `max_depth` and `min_samples_split`.\n", "\n", "Then define a new `GridSearchCV` object and find the best parameters.\n", "\n", "When searching for the best parameters, we typically select the ones which give the best results on the validation set, which is distinct from the training and test sets. `GridSearchCV` includes cross-validation, so we can pass it the training data directly. As part of cross-validation, the original training data will be repeatedly split into various training and validation sets."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "from sklearn.model_selection import GridSearchCV\n", "\n", "parameters  = [{'max_depth': [3, 4, 7], \"min_samples_split\": [5, 10, 20]}] \n", "\n", "gridCV = GridSearchCV(dtc, parameters, cv=10)\n", "\n", "gridCV.fit(X_train, y_train)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["What are your best parameters?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "gridCV.best_params_\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Now we can re-train our model using these parameters. Set the parameters of the tree to be the best ones given by the grid search, and train the model again:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "dtc.set_params(**gridCV.best_params_)\n", "dtc.fit(X_train, y_train)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Display the final tree:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["plt.figure(figsize=(40, 8))\n", "tree.plot_tree(dtc, \n", "               filled=True, \n", "               rounded=True,\n", "               max_depth=6,\n", "               proportion=True,\n", "               fontsize=10,\n", "               feature_names=X_train.columns)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Compute its accuracy on the train and test sets:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "from sklearn.metrics import accuracy_score\n", "\n", "print(accuracy_score(y_train, dtc.predict(X_train)))\n", "print(accuracy_score(y_test, dtc.predict(X_test)))\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Finally check the classification report for the test set:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "print(classification_report(y_test, dtc.predict(X_test)))\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Feature importance"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Decision trees have the advantage of providing a feature importance, a score allowing you to rank all features by their importance for the model when predicting the outcome. With `sklearn`, you can access it with the attribute called `feature_importances_`.\n", "\n", "Take a look at the `feature_importances_` attribute:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "dtc.feature_importances_\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["That's hard to read. The array gives a number for each column in our training set, in the same order. A better way to visualise it would be to put it in a table, so let's do that.\n", "\n", "Create a new DataFrame where the data will be the feature importances from above, and the index will be the list of columns from our training data. Call this DataFrame `importances_df`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "importances_df = pd.DataFrame(\n", "    dtc.feature_importances_,\n", "    columns=[\"importance\"],\n", "    index=X_train.columns\n", ")\n", "importances_df.sort_values(\"importance\", ascending=False).head()\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Plot it as a bar plot:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "importances_df.sort_values(\"importance\", ascending=False).plot(kind=\"bar\", figsize=(20,7))\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["What's the most important feature?"]}]}