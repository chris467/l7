{"metadata": {"@webio": {"lastCommId": null, "lastKernelId": null}, "celltoolbar": "None", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7"}, "rise": {"overlay": "<div class='cs-logo'><img src='../../../static/img/cspark-logo.png'></div>", "scroll": true, "theme": "white"}}, "nbformat": 4, "nbformat_minor": 4, "cells": [{"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# Nonlinear Relationships\n", "\n", "Linear Regression can in fact model nonlinear relationships in data, provided it is given the appropriate features.\n", "\n", "In this practical, we use an alternative dataset which will benefit from feature engineering. We focus here on univariate data in order to familiarise yourself with the process. You are welcome to use any transformation you like to improve your model fit.\n", "\n", "We will work with `sklearn`, `numpy`, `pandas` and `matplotlib` libraries.\n", "\n", "**Possible transformations**:\n", "\n", "- Polynomial features: $x^2, x^3, x^4, \\ldots$. Take a look at `sklearn.preprocessing.PolynomialFeatures` for a quick way to derive these features.\n", "- Sinusoidal features: $\\sin(x), \\cos(x), \\sin(0.5x), \\cos(0.5x), \\ldots$. \n", "- Any other standard functions, e.g. `log`, `exp`, `tanh`. Most familiar functions can be found within `numpy`. \n", "- 'Bump'-type functions e.g. the Gaussian density $f(x; c, \\sigma) = \\exp(-(x-c)^2/2\\sigma)$. Try varying the center $c$ and the bandwidth $\\sigma$.\n", "- Compositions of any of the above.\n", "\n", "**Additional hints**:\n", "\n", "- You may find it useful to use `np.hstack` again in order to build up your matrix of derived features. \n", "- In order to debug your model fit (why have my transformations not yielded a good fit?), it may be helpful to plot the raw transformations against the target data.\n", "- When considering how well your model may perform in practice, take a look at the fit outside the support of your data (i.e. below $\\min(x)$ and above $\\max(x)$).\n", "- Have fun!"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["We start by importing the relevant libraries and defining several helper functions:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["def generate_data(n=200):\n", "    \"\"\"\n", "    Generate data for the Linear Regression exercises. In our examples we \n", "    have used the default value of n=200.\n", "    \"\"\"\n", "    np.random.seed(1000)\n", "    \n", "    x = (np.random.rand(n) - 0.2) * 160\n", "    y = 1.8 * np.log(x + 36) + np.exp(x/10 - 10.5) + 0.02 * x  + np.random.randn(n) * 2\n", "    x = x.reshape(n,1)\n", "    \n", "    return x, y\n", "    \n", "def generate_data_nonlinear(n=200):\n", "    \"\"\"\n", "    Generate non-linear data for the Linear Regression exercises. In our examples we \n", "    have used the default value of n=200.\n", "    \"\"\"\n", "    x, y = generate_data(200)\n", "    s = float(\"\".join([chr(47+x) for x in [1,-1,1,6]]))\n", "    f = getattr(np, \"\".join([chr(92+x) for x in [23,13,18]]))\n", "    y = f(s*np.abs(x)) + 0.25*np.random.randn(*x.shape)\n", "    return x, y\n", "\n", "def generate_data3d(n=200):\n", "    \"\"\"\n", "    Generate 3D data for the Linear Regression exercises. In our examples we \n", "    have used the default value of n=200.\n", "    \"\"\"\n", "    np.random.seed(3)\n", "    \n", "    x = (np.random.multivariate_normal(np.array([1,2]), np.array([[3, 2.6], [2.6, 3]]), size=n))\n", "    w = np.random.randn(2)\n", "    v = x @ w\n", "    y = np.exp(np.sqrt(np.abs(v-np.percentile(v, 0.9)))) + 0.08 * v  + np.random.randn(n) * 0.3\n", "    \n", "    return x, y"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["We load the data and make a scatter plot of the data in order to understand what features might be useful."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# load the data\n", "np.random.seed(1000)\n", "x2, y2 = generate_data_nonlinear(200)\n", "\n", "# make a scatter plot\n", "plt.scatter(x2, y2);"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["**Task**:\n", "\n", "- Fit a standard linear regression model to the data."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.linear_model import LinearRegression\n", "# Fit the model and extract the parameter vector w2\n", "# Your code here...\n", "model = LinearRegression().fit(x2, y2)\n", "w2 = np.array([model.intercept_] + [coef for coef in model.coef_])\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["**Tasks**:\n", "\n", "1. Plot the results of your linear model using the `plot_results` function.\n", "2. Calculate the model's $R^2$ using `model.score`."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["You may find the following plotting function useful. It takes the following arguments:\n", "\n", "* `x`, `y`: The data for which to perform the scatter plot\n", "* `predicted`: The predicted values for the `x_plot` array defined below. For `sklearn`, this should be the result of `model.predict(x_plot)`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["x_plot = np.linspace(-30,120, 200).reshape(200,1)\n", "\n", "def plot_results(x, y, predicted, color=\"#e1851e\", do_scatter=True):\n", "    do_scatter and plt.scatter(x, y, alpha=.7)\n", "    plt.plot(x_plot, predicted, color=color, linewidth=4, alpha=0.8)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "plot_results(x2, y2, model.predict(x_plot))\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# What is the model score?\n", "# Your result here...\n", "print(\"R2 for nonlinear fit is: {:.3f}\".format(model.score(x2, y2)))\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Feature extraction\n", "\n", "**Tasks**:\n", "1. Create a variety of features that you think may be useful (see the list given above) and concatenate them into an $X_2$ matrix using `np.hstack`. For example, using polynomial features, the desired result would be:\n", "<br>\n", "$$X_2 = \\begin{bmatrix} 1 & x_1 & x_1^2 & x_1^3 & \\ldots \\\\ 1 & x_2 & x_2^2 & x_2^3 & \\ldots \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ 1 & x_n & x_n^2 & x_n^3 & \\ldots \\end{bmatrix}$$\n", "<br>\n", "2. Fit an `sklearn` `LinearRegression` model using this matrix and with targets `y2`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "X2 = np.hstack((np.ones((200,1)), x2, x2**2, x2**3, x2**4, x2**5))\n", "model_poly = LinearRegression().fit(X2, y2)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["**Tasks**\n", "\n", "1. Apply the same transformations as above to the vector `x_plot`, and save the results to a variable `X_plot` (note the capital X).\n", "2. Plot your model using `plot_results`. You'll need to feed in the predictions from `model.predict(X_plot)` (now on the matrix constructed in (1)).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "X_plot = np.hstack((np.ones((200,1)), x_plot, x_plot**2, x_plot**3, x_plot**4, x_plot**5))\n", "plot_results(x2, y2, model_poly.predict(X_plot))\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["**Tasks**\n", "\n", "1. Find your model's $R^2$ using `model.score`.\n", "2. Try some different features and try to improve this!"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "print(\"R2 for nonlinear fit is: {:.3f}\".format(model_poly.score(X2, y2)))\n"]}]}